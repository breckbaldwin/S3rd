{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8270b53b",
   "metadata": {},
   "source": [
    "%md\n",
    "\n",
    "# Simulating impact of peer review on supporting meritorious science\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a67f209",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "random_sample() takes at most 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80323/1768110560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msci2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnFunded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mwinner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reputation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mwinner\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resources'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: random_sample() takes at most 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "import random\n",
    "rng = default_rng()\n",
    "\n",
    "nScientists = 10\n",
    "\n",
    "sci = [{}] * nScientists\n",
    "sci2 = [{}] * nScientists\n",
    "\n",
    "for i in range(nScientists):\n",
    "    sci[i] = {'id': i, 'reputation': .1, 'merit': .1, 'resources': 0}\n",
    "    if i%10 == 0:\n",
    "        sci[i]['merit'] += 0\n",
    "    sci2[i] = {'id': i, 'reputation': .1, 'merit': .1, 'resources': 0}\n",
    "    if i%10 == 0:\n",
    "        sci2[i]['merit'] += 0\n",
    "        \n",
    "start = 0\n",
    "nApplicants = nScientists\n",
    "nRfp = 15\n",
    "nFunded = 3\n",
    "threshold = 0.2\n",
    "sd_merit = 0.1\n",
    "x = []\n",
    "y = []\n",
    "y2 = []\n",
    "\n",
    "for rfp in range(0, nRfp):\n",
    "    for i in range(0, nApplicants):\n",
    "        sci[i]['score'] = rng.normal(sci[i]['merit'], sd_merit, 1)[0] +\\\n",
    "                                 sci[i]['reputation']\n",
    "        sci2[i]['score'] = rng.normal(sci2[i]['merit'], sd_merit, 1)[0] +\\\n",
    "                                  sci2[i]['reputation']\n",
    "    sorted_scores = sorted(sci, key=lambda s: s['score'], reverse=True)\n",
    "    for winner in sorted_scores[0:nFunded]:\n",
    "        winner['reputation'] += .1\n",
    "        winner['resources'] += 1\n",
    "\n",
    "    candidates = [s for s in sci2 if s['score'] > threshold]\n",
    "    for winner in sample(candidates, nFunded):\n",
    "        winner['reputation'] += .1\n",
    "        winner['resources'] += 1\n",
    "\n",
    "    jitter = .1\n",
    "    for i in range(0, nScientists):\n",
    "        x.append(rng.normal(rfp, jitter, 1)[0])\n",
    "        y.append(rng.normal(sci[i]['resources'], jitter, 1)[0])\n",
    "        y2.append(rng.normal(sci2[i]['resources'], jitter, 1)[0])\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "df['resources'] = y\n",
    "df2['resources'] = y2\n",
    "df['rfp_count'] = x\n",
    "df2['rfp_count'] = x\n",
    "df['selection method'] = ['Top N totally ordered by score'] * len(x)\n",
    "df2['selection method'] = ['Random N score above threshold'] * len(x)\n",
    "\n",
    "\n",
    "plot = (\n",
    "    plotnine.ggplot(mapping=plotnine.aes(x='rfp_count', y='resources', group = 'selection method'))\n",
    "    + plotnine.geom_point(data=df, mapping=plotnine.aes(color='selection method'), size=.2) \n",
    "    + plotnine.geom_point(data=df2, mapping=plotnine.aes(color='selection method'), size=.2)\n",
    "    + plotnine.ggtitle(f\"{nFunded} awards per funding cycle, {nApplicants} participants\")\n",
    "    + plotnine.labs(x=\"Iterations of funding cycle\", y=\"Accumulated resources over time\")\n",
    "    + plotnine.theme_xkcd()\n",
    "    )\n",
    "\n",
    "print(plot)\n",
    "            \n",
    "#print(sci)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
